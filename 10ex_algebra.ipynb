{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. PCA on 3D dataset\n",
    "\n",
    "* Generate a dataset simulating 3 features, each with N entries (N being ${\\cal O}(1000)$). Each feature is made by random numbers generated according the normal distribution $N(\\mu,\\sigma)$ with mean $\\mu_i$ and standard deviation $\\sigma_i$, with $i=1, 2, 3$. Generate the 3 variables $x_{i}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      " [[ 0.09817224 -0.17442946 -0.49086382 ... -0.0711662   1.76637867\n",
      "  -0.93113195]\n",
      " [ 1.69868646 -3.4567745   0.08893523 ...  0.91670948  2.83457295\n",
      "  -4.26535549]\n",
      " [ 1.89503093 -3.80563342 -0.89279241 ...  0.77437709  6.3673303\n",
      "  -6.1276194 ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "x1 = np.random.normal(loc = 0, scale = 1, size = N)\n",
    "x2 = x1 + np.random.normal(loc = 0, scale = 3, size = N)\n",
    "x3 = 2 * x1 + x2\n",
    "\n",
    "M = np.array([x1, x2, x3])\n",
    "\n",
    "print (\"Dataset:\\n\", M, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the eigenvectors and eigenvalues using the eigendecomposition of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance matrix:\n",
      "\n",
      "[[ 0.94803896  0.96083859  2.85691651]\n",
      " [ 0.96083859 10.45382044 12.37549761]\n",
      " [ 2.85691651 12.37549761 18.08933062]] \n",
      "\n",
      "\n",
      "### Using the eigendecomposition of the covariance matrix ###\n",
      "\n",
      "Eigenvalues:\n",
      " [ 2.75326221e+01+0.j -6.67272072e-16+0.j  1.95856789e+00+0.j] \n",
      "\n",
      "Real eigenvalues:\n",
      " [ 2.75326221e+01 -6.67272072e-16  1.95856789e+00] \n",
      "\n",
      "Eigenvectors:\n",
      " [[-0.10743502 -0.81649658  0.56726629]\n",
      " [-0.58732146 -0.40824829 -0.69884679]\n",
      " [-0.80219151  0.40824829  0.4356858 ]] \n",
      "\n",
      "The decomposition was successful.\n"
     ]
    }
   ],
   "source": [
    "### Using the eigendecomposition of the covariance matrix ###\n",
    "\n",
    "# compute the mean of each sequence (row) and set the right shape\n",
    "M_mean = M.mean(axis = 1)[:, np.newaxis]\n",
    "\n",
    "# re-center each sequence (row) around its mean\n",
    "w = M - M_mean\n",
    "\n",
    "# compute the covariance matrix\n",
    "cov = w.dot(w.T) / (N - 1)\n",
    "print(\"\\nCovariance matrix:\\n\")\n",
    "print(cov, \"\\n\")\n",
    "\n",
    "l, V = la.eig(cov)\n",
    "print(\"\\n### Using the eigendecomposition of the covariance matrix ###\\n\")\n",
    "print(\"Eigenvalues:\\n\", l, '\\n')\n",
    "print(\"Real eigenvalues:\\n\", np.real_if_close(l), '\\n')\n",
    "\n",
    "print(\"Eigenvectors:\\n\", V, '\\n')\n",
    "\n",
    "D1 = np.dot(V, np.dot(np.diag(np.real_if_close(l)), la.inv(V)))\n",
    "if (np.allclose(cov, D1)):\n",
    "    print(\"The decomposition was successful.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the eigenvectors and eigenvalues using the SVD. Check that the two procedures yield to same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: U = (3, 3) D: (3,) V^T: (3, 3) \n",
      "\n",
      "Eigenvalues:\n",
      " [2.75326221e+01 1.95856789e+00 7.88923421e-16] \n",
      "\n",
      "U:\n",
      " [[-0.10743502  0.56726629 -0.81649658]\n",
      " [-0.58732146 -0.69884679 -0.40824829]\n",
      " [-0.80219151  0.4356858   0.40824829]] \n",
      "\n",
      "V^T:\n",
      " [[-0.10743502 -0.58732146 -0.80219151]\n",
      " [ 0.56726629 -0.69884679  0.4356858 ]\n",
      " [ 0.81649658  0.40824829 -0.40824829]] \n",
      "\n",
      "D:\n",
      " [[2.75326221e+01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.95856789e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.88923421e-16]] \n",
      "\n",
      "SVD:\n",
      " [[ 0.94803896  0.96083859  2.85691651]\n",
      " [ 0.96083859 10.45382044 12.37549761]\n",
      " [ 2.85691651 12.37549761 18.08933062]] \n",
      "\n",
      "The decomposition was successful.\n",
      "\n",
      "The eigenvalues obtained by SVD and eigendecomposition are the same.\n"
     ]
    }
   ],
   "source": [
    "### Using the the Singular Value Decomposition of the covariance matrix ###\n",
    "\n",
    "# perform the SVD\n",
    "U, S, Vt = la.svd(cov)\n",
    "\n",
    "print(\"shapes: U =\", U.shape, \"D:\", S.shape, \"V^T:\", Vt.shape, '\\n')\n",
    "print(\"Eigenvalues:\\n\", S, '\\n')\n",
    "print(\"U:\\n\", U, '\\n')\n",
    "print(\"V^T:\\n\", Vt, '\\n')\n",
    "\n",
    "# Let's verify the definition of SVD by hand\n",
    "D2 = np.zeros(np.shape(cov))\n",
    "for i in range(min(np.shape(cov))):\n",
    "    D2[i, i] = S[i]\n",
    "print(\"D:\\n\", D2, '\\n')\n",
    "\n",
    "SVD = np.dot(U, np.dot(D2, Vt))\n",
    "print(\"SVD:\\n\", SVD, '\\n')\n",
    "\n",
    "if (np.allclose(cov, SVD)):\n",
    "    print(\"The decomposition was successful.\\n\")\n",
    "\n",
    "if (np.allclose(np.sort(S), np.sort(np.real_if_close(l)))):\n",
    "    print(\"The eigenvalues obtained by SVD and eigendecomposition are the same.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redefine the data according to the new basis from the PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the data, in both the original and the new basis. The figure should have 2 rows (the original and the new basis) and 3 columns (the $[x_0, x_1]$, $[x_0, x_2]$ and $[x_1, x_2]$ projections) of scatter plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. PCA on a nD dataset\n",
    "\n",
    "* Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normally distributed, with a standard deviation much smaller (e.g. a factor 20) than those used to generate the $x_1$ and $x_2$. Repeat the PCA procedure and compare the results with what you have obtained before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Optional**: PCA on the MAGIC dataset\n",
    "\n",
    "Perform a PCA on the magic04.data dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset and its description on the proper data directory\n",
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P data/\n",
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
