{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named \"data_int.txt\". Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named \"data_float.txt\". Use the `cat` command to print the content of the file.\n",
    "+ load the txt file of the previous point and convert it to a csv file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "l = np.arange(1, 11)\n",
    "\n",
    "out_file = \"data/data_int.txt\"\n",
    "with open(out_file, 'w') as outfile:\n",
    "    outfile.write(str(l) + '\\n')\n",
    "\n",
    "!cat data/data_int.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0, 2.0, 3.0, 4.0, 5.0\n",
      "6.0, 7.0, 8.0, 9.0, 10.0\n",
      "11.0, 12.0, 13.0, 14.0, 15.0\n",
      "16.0, 17.0, 18.0, 19.0, 20.0\n",
      "21.0, 22.0, 23.0, 24.0, 25.0\n"
     ]
    }
   ],
   "source": [
    "m = np.linspace(1, 25, 25, 'float')\n",
    "m = m.reshape(5, 5)\n",
    "\n",
    "\n",
    "out_file = \"data/data_float.txt\"\n",
    "with open(out_file, 'w') as outfile:\n",
    "    for i in range(len(m[:, 0])):\n",
    "        for j in range(len(m[0, :])):\n",
    "            outfile.write(str(m[i, j]))\n",
    "            if j < len(m[0, :])-1:\n",
    "                outfile.write(\", \")\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "!cat data/data_float.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data/output.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    with open(\"data/data_float.txt\", \"r\") as data_file:\n",
    "        for line in csv.reader(data_file, delimiter = ','):\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"data/user_data.json\"))\n",
    "\n",
    "data_filtered = []\n",
    "for i in range(len(data)):\n",
    "    if data[i][\"CreditCardType\"] == \"American Express\":\n",
    "        data_filtered.append(data[i])\n",
    "\n",
    "headers = [\"ID\", \"JobTitle\", \"EmailAddress\", \"FirstNameLastName\", \"CreditCard\", \"CreditCardType\"] # set a headers string\n",
    "line = [] # initialize line to write\n",
    "with open(\"data/user_data_filtered.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers) # write the headers first\n",
    "    for i in range(len(data_filtered)):\n",
    "        for el in headers:\n",
    "            line.append(data_filtered[i][el])\n",
    "        writer.writerow(line) # write row (i) from data_filtered\n",
    "        line = [] # clear variable line for reading row (i+1) from data_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/credit_card.dat','rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8 # size of the word in bytes\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        if word_counter > 10: break\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        if i == 0: print ('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format('HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS'))\n",
    "        print('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format(head, fpga, tdc_chan, orb_cnt, bx, tdc_meas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Optional**: load the remote file:\n",
    "\n",
    "- https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "\n",
    "with Pandas and create a scatter plot with all possible combinations of the following features:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
